"""
In-Class Activity: Exploratory Data Analysis (EDA) with Starbucks Drinks

Dataset: starbucks_drinkMenu_expanded.csv (available in Canvas and GitHub)
Goal: Understand what the dataset contains, identify patterns, and create a meaningful visualization.
"""

print("*************** Part 1 ***************")

"""
1. Load the CSV file into a pandas DataFrame
2. Print:
- The full DataFrame (‚ö†Ô∏è observe what happens)
- The first 5 rows
- The last 5 rows

3. Display:
- Column names
- Dataset info (data types + missing values)
- Descriptive statistics

üí° Reflection questions:

A) Why is printing the entire DataFrame usually a bad idea?
B) Which columns are numeric? Which are categorical?
C) Do the statistics make sense for food and drinks?
"""
import pandas as pd
# pd.set_option('display.max_columns', None)
df = pd.read_csv("logs/starbucks_drinkMenu_expanded.csv")

print(df.head())
print(df.tail())

print(df.columns)
print(df.info())
print(df.describe())
print("*************** Part 2 ***************")
"""
1. Select and print only these columns:
- Beverage
- Caffeine (mg)
- Sodium (mg)

Display:
- One specific row (your choice)
- Two different rows (your choice)
- Those same rows, but only for two columns

üí° Reflection questions:
A) When would you select rows vs columns?
B) What kind of question would each selection help answer?
"""
print(df[['Beverage', 'Caffeine (mg)', 'Sodium (mg)']])

print(df.loc[10])
print(df.loc[[10, 20]])
print(df.loc[[10,20],["Calories","Caffeine (mg)"]])

print("*************** Part 3 ***************")

"""
1. Create a table showing where missing values exist
2. Count how many missing values each column has

üí° Reflection questions:

A) Which columns have missing values?
B) Would you drop, fill, or ignore them? Why?
"""

missing_values = {
    "Feature":df.columns,
    "Missing Values":df.isna().sum(),
    "Percentage of Missing":(df.isna().sum() / len(df)) * 100
}
print(pd.DataFrame(missing_values))

print("*************** Part 4 ***************")
"""
1. Filter the dataset to show beverages with:
- Calories below 100
- Improve the filter to show beverages with:
- Calories below 100 AND
- Caffeine below 50 mg

‚ö†Ô∏è Challenge:
Make sure your condition works correctly. If it doesn‚Äôt, debug it.

üí° Reflection questions:
A) What kind of customer might this filter represent?
B) Why do we need parentheses in compound conditions?
"""
condition1 = df["Calories"]<100
low_cal = df[condition1]
print(low_cal)

condition2 = df["Caffeine (mg)"]<50
lowCalLowCaf = df[condition1 & condition2]
print(lowCalLowCaf)

print(df[condition1 & ~condition2])
print("*************** Part 5 ***************")
"""
1. Group the dataset by Beverage_category
2. Compute the average calories per category
3. Print the result

üí° Reflection questions:
A) Which category is the most calorie-dense on average?
B) Why is the mean a reasonable (or not) choice here?
"""

print(df.groupby("Beverage_category")["Calories"].mean())
print("*************** Part 6 ***************")

"""
1. Create a new DataFrame containing only numeric nutrition columns
2. Compute the correlation matrix
3. Plot a correlation heatmap using Plotly

üí° Reflection questions:

A) Which nutrients are strongly correlated?
B) Are there any surprising relationships?
C) Why does correlation not imply causation?
"""

n_df = df.select_dtypes(include='number')

print(n_df.head())

corr = n_df.corr()

import plotly.express as px

fig = px.imshow(
    corr,
    text_auto=True,
    title="Correlation Matrix Heatmap"
)
fig.show()